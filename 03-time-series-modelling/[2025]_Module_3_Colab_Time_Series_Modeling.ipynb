{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1wruXmPvYWB",
        "outputId": "fdce6bc1-1cea-496a-d987-947d2332daea"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vPfvfETy1Z0",
        "outputId": "5412a3d8-5d44-418a-f2cb-b9d8845869ad"
      },
      "outputs": [],
      "source": [
        "# read files shared via google-drive-link\n",
        "# https://stackoverflow.com/questions/62759748/downloading-data-from-a-shared-google-drive-link-in-google-colab\n",
        "\n",
        "!pip uninstall gdown -y && pip install gdown\n",
        "!gdown -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge4C2c2_w7Ac"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Fin Data Sources\n",
        "import yfinance as yf\n",
        "import pandas_datareader as pdr\n",
        "\n",
        "#Data viz\n",
        "import plotly.graph_objs as go\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "import time\n",
        "from datetime import date\n",
        "\n",
        "# for graphs\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX7x0Ywww_fD"
      },
      "source": [
        "# 0) Dataset for Modeling: Final Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddC_AcGUat5w"
      },
      "source": [
        "## 0.1) Importing data from Drive & defining variable sets\n",
        "* automated version need to have a daily updated file/database entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-s1660YysQd",
        "outputId": "2800f6bf-0833-499c-fe2c-583e05e6d023"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/62759748/downloading-data-from-a-shared-google-drive-link-in-google-colab\n",
        "# truncated data from Module 2: https://drive.google.com/file/d/1mb0ae2M5AouSDlqcUnIwaHq7avwGNrmB/view?usp=sharing\n",
        "!gdown https://drive.google.com/file/d/1mb0ae2M5AouSDlqcUnIwaHq7avwGNrmB/view?usp=sharing --fuzzy -O /content/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsPVf4XT1JAZ"
      },
      "outputs": [],
      "source": [
        "# truncated\n",
        "# df = pd.read_parquet(\"/content/stocks_df_combined_trunc_2014_2023.parquet.brotli\", )\n",
        "\n",
        "# full dataset for 33 stocks\n",
        "df_full = pd.read_parquet(\"/content/stocks_df_combined_2025_06_13.parquet.brotli\", )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fiZOGqG1puH",
        "outputId": "30c6c54f-c5e4-48d0-dca0-5ed55afa0dbc"
      },
      "outputs": [],
      "source": [
        "df_full.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzFRVbklIW4q",
        "outputId": "fc5710e4-a910-42b1-fb65-bb523eca7a1f"
      },
      "outputs": [],
      "source": [
        "df_full.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfDKpGwtIawQ",
        "outputId": "830f7eb6-c4db-4bae-9937-9b2223da5ca8"
      },
      "outputs": [],
      "source": [
        "# growth indicators (but not future growth)\n",
        "GROWTH = [g for g in df_full.keys() if (g.find('growth_')==0)&(g.find('future')<0)]\n",
        "GROWTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O28ePT2AI892"
      },
      "outputs": [],
      "source": [
        "# leaving only Volume ==> generate ln(Volume)\n",
        "OHLCV = ['Open','High','Low','Close','Adj Close_x','Volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVcJZDyGbH2N"
      },
      "outputs": [],
      "source": [
        "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7kZrwZiIpCN",
        "outputId": "22f03020-b51c-433d-a7d2-f79431ef24c2"
      },
      "outputs": [],
      "source": [
        "TO_PREDICT = [g for g in df_full.keys() if (g.find('future')>=0)]\n",
        "TO_PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tZF13UbOXGF",
        "outputId": "1248465e-9707-46af-ba68-0ef7f0879150"
      },
      "outputs": [],
      "source": [
        "TO_DROP = ['Year','Date','index_x', 'index_y', 'index', 'Quarter','Adj Close_y'] + CATEGORICAL + OHLCV\n",
        "TO_DROP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgBFjAADfXSp",
        "outputId": "9c326bac-4822-4d24-df82-b98369637be7"
      },
      "outputs": [],
      "source": [
        "# let's define on more custom numerical features\n",
        "df_full['ln_volume'] = df_full.Volume.apply(lambda x: np.log(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lukhBLIcfW8g"
      },
      "outputs": [],
      "source": [
        "# manually defined features\n",
        "CUSTOM_NUMERICAL = ['SMA10', 'SMA20', 'growing_moving_average', 'high_minus_low_relative','volatility', 'ln_volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpRKmVtaf6is"
      },
      "outputs": [],
      "source": [
        "# All Supported Ta-lib indicators: https://github.com/TA-Lib/ta-lib-python/blob/master/docs/funcs.md\n",
        "\n",
        "TECHNICAL_INDICATORS = ['adx', 'adxr', 'apo', 'aroon_1','aroon_2', 'aroonosc',\n",
        " 'bop', 'cci', 'cmo','dx', 'macd', 'macdsignal', 'macdhist', 'macd_ext',\n",
        " 'macdsignal_ext', 'macdhist_ext', 'macd_fix', 'macdsignal_fix',\n",
        " 'macdhist_fix', 'mfi', 'minus_di', 'mom', 'plus_di', 'dm', 'ppo',\n",
        " 'roc', 'rocp', 'rocr', 'rocr100', 'rsi', 'slowk', 'slowd', 'fastk',\n",
        " 'fastd', 'fastk_rsi', 'fastd_rsi', 'trix', 'ultosc', 'willr',\n",
        " 'ad', 'adosc', 'obv', 'atr', 'natr', 'ht_dcperiod', 'ht_dcphase',\n",
        " 'ht_phasor_inphase', 'ht_phasor_quadrature', 'ht_sine_sine', 'ht_sine_leadsine',\n",
        " 'ht_trendmod', 'avgprice', 'medprice', 'typprice', 'wclprice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncPdBnx13ilm",
        "outputId": "bb3273f2-b2a8-4fce-8fb5-81e7aea0cbdd"
      },
      "outputs": [],
      "source": [
        "TECHNICAL_PATTERNS = [g for g in df_full.keys() if g.find('cdl')>=0]\n",
        "print(f'Technical patterns count = {len(TECHNICAL_PATTERNS)}, examples = {TECHNICAL_PATTERNS[0:5]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUa1pIvB4o5w"
      },
      "outputs": [],
      "source": [
        "MACRO = ['gdppot_us_yoy', 'gdppot_us_qoq', 'cpi_core_yoy', 'cpi_core_mom', 'FEDFUNDS',\n",
        " 'DGS1', 'DGS5', 'DGS10']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nakB0XZA1uFq"
      },
      "outputs": [],
      "source": [
        "NUMERICAL = GROWTH + TECHNICAL_INDICATORS + TECHNICAL_PATTERNS + CUSTOM_NUMERICAL + MACRO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri9F9mIwIuVa",
        "outputId": "895ef74e-8ea7-4dc4-a9a2-3b65a9cd8c36"
      },
      "outputs": [],
      "source": [
        "# CHECK: NO OTHER INDICATORS LEFT\n",
        "OTHER = [k for k in df_full.keys() if k not in OHLCV + CATEGORICAL + NUMERICAL + TO_DROP]\n",
        "OTHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zv_OOrK1ulV",
        "outputId": "890fe5d4-0dd1-4800-9fef-630d2420f9ed"
      },
      "outputs": [],
      "source": [
        "df_full.Ticker.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bPKU1Z612OK",
        "outputId": "2e1c07db-dc4e-4bf1-86be-4bdb1c40cedc"
      },
      "outputs": [],
      "source": [
        "# tickers, min-max date, count of daily observations\n",
        "df_full.groupby(['Ticker'])['Date'].agg(['min','max','count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmIpnwsJLvtI",
        "outputId": "0c767c0d-ec2b-4810-b853-917278c2195b"
      },
      "outputs": [],
      "source": [
        "# truncated df_full with 25 years of data (and defined growth variables)\n",
        "df = df_full[df_full.Date>='2000-01-01']\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1idq4ieQ_ac",
        "outputId": "b6d7e088-7dc1-4343-fa64-62876e914eca"
      },
      "outputs": [],
      "source": [
        "# let look at the features count and df size:\n",
        "df[NUMERICAL].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK6TYOZIcBNU"
      },
      "source": [
        "## 0.2) [Code snippet 1] Generating dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjfA2dyIeCDn",
        "outputId": "b333a42a-7b7c-428b-f8b5-be61cb76cfdf"
      },
      "outputs": [],
      "source": [
        "# what are the categorical features?\n",
        "CATEGORICAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa-AoEDeLX4x",
        "outputId": "492b3c90-05b6-49b2-9188-5859154769e4"
      },
      "outputs": [],
      "source": [
        "# dummy variables are not generated from Date and numeric variables\n",
        "df.loc[:,'Month'] = df.Month.dt.strftime('%B')\n",
        "df.loc[:,'Weekday'] = df.Weekday.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuAlw48XKjE5"
      },
      "outputs": [],
      "source": [
        "# Generate dummy variables (no need for bool, let's have int32 instead)\n",
        "dummy_variables = pd.get_dummies(df[CATEGORICAL], dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dovxcVkk-72S"
      },
      "outputs": [],
      "source": [
        "# TODO 1: define more categorical features, e.g. all combinations for <September+weekday>  (you'll see that September is actually an important dummy in one of the models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzzG2DfZKpFn",
        "outputId": "304cae17-f46e-4843-bd21-2b3534aab899"
      },
      "outputs": [],
      "source": [
        "dummy_variables.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxLHnVE3RaaU"
      },
      "outputs": [],
      "source": [
        "# get dummies names in a list\n",
        "DUMMIES = dummy_variables.keys().to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0e65F71Kl15"
      },
      "outputs": [],
      "source": [
        "# Concatenate the dummy variables with the original DataFrame\n",
        "df_with_dummies = pd.concat([df, dummy_variables], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qim1MIwUWE9",
        "outputId": "7fcd1318-d33f-4aae-830c-38eed3ae5b19"
      },
      "outputs": [],
      "source": [
        "df_with_dummies[NUMERICAL+DUMMIES].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZl0ilI_Vx-O"
      },
      "source": [
        "## 0.3) [Code Snippet 2] Correlation analysis\n",
        "* first approximation of \"important\" variables correlated with all variables we want to predict (TO_PREDICT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4EVjxDMWHEP",
        "outputId": "d2b5d5c8-f970-4bcf-ed16-a5375c5641bd"
      },
      "outputs": [],
      "source": [
        "TO_PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no3MkU5AWCDF"
      },
      "outputs": [],
      "source": [
        "corr_is_positive_growth_30d_future = df_with_dummies[NUMERICAL+DUMMIES+TO_PREDICT].corr()['is_positive_growth_30d_future']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtcXzUDaWshV"
      },
      "outputs": [],
      "source": [
        "# create a dataframe for an easy way to sort\n",
        "corr_is_positive_growth_30d_future_df = pd.DataFrame(corr_is_positive_growth_30d_future)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n9rCxGhGXavp",
        "outputId": "40110cc6-d41f-4def-8cc7-295893db6bed"
      },
      "outputs": [],
      "source": [
        "corr_is_positive_growth_30d_future_df.sort_values(by='is_positive_growth_30d_future').head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "qXk1b0goXfsI",
        "outputId": "525ee60a-8efe-451f-ef25-f541c55238c2"
      },
      "outputs": [],
      "source": [
        "corr_is_positive_growth_30d_future_df.sort_values(by='is_positive_growth_30d_future').tail(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWrEqmLSXml3"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_30d = df_with_dummies[NUMERICAL+DUMMIES+TO_PREDICT].corr()['growth_future_30d']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY06BtPwXzWc"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_30d_df = pd.DataFrame(corr_growth_future_30d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0I6hcmFcX1G8",
        "outputId": "4bce74c3-0080-414f-a0d4-e924fd0578f1"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_30d_df.sort_values(by='growth_future_30d').head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "piFZJuu7X98b",
        "outputId": "0855440e-73dd-4fe3-a5bc-aec51d5bd214"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_30d_df.sort_values(by='growth_future_30d').tail(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDcUuE1atTM8"
      },
      "source": [
        "## 0.4) [Code snippet 3] Temporal split of ~25 years of data (by date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loo6ktrtvKrn"
      },
      "outputs": [],
      "source": [
        "def temporal_split(df, min_date, max_date, train_prop=0.7, val_prop=0.15, test_prop=0.15):\n",
        "    \"\"\"\n",
        "    Splits a DataFrame into three buckets based on the temporal order of the 'Date' column.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): The DataFrame to split.\n",
        "        min_date (str or Timestamp): Minimum date in the DataFrame.\n",
        "        max_date (str or Timestamp): Maximum date in the DataFrame.\n",
        "        train_prop (float): Proportion of data for training set (default: 0.6).\n",
        "        val_prop (float): Proportion of data for validation set (default: 0.2).\n",
        "        test_prop (float): Proportion of data for test set (default: 0.2).\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: The input DataFrame with a new column 'split' indicating the split for each row.\n",
        "    \"\"\"\n",
        "    # Define the date intervals\n",
        "    train_end = min_date + pd.Timedelta(days=(max_date - min_date).days * train_prop)\n",
        "    val_end = train_end + pd.Timedelta(days=(max_date - min_date).days * val_prop)\n",
        "\n",
        "    # Assign split labels based on date ranges\n",
        "    split_labels = []\n",
        "    for date in df['Date']:\n",
        "        if date <= train_end:\n",
        "            split_labels.append('train')\n",
        "        elif date <= val_end:\n",
        "            split_labels.append('validation')\n",
        "        else:\n",
        "            split_labels.append('test')\n",
        "\n",
        "    # Add 'split' column to the DataFrame\n",
        "    df['split'] = split_labels\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0gVQMUEyNIc"
      },
      "outputs": [],
      "source": [
        "min_date_df = df_with_dummies.Date.min()\n",
        "max_date_df = df_with_dummies.Date.max()\n",
        "\n",
        "df_with_dummies = temporal_split(df_with_dummies,\n",
        "                                 min_date = min_date_df,\n",
        "                                 max_date = max_date_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "X-aPYFprylhp",
        "outputId": "acb6f3be-ebde-40ce-e84d-975228bf031b"
      },
      "outputs": [],
      "source": [
        "df_with_dummies['split'].value_counts()/len(df_with_dummies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPoJV5bnUnKr"
      },
      "outputs": [],
      "source": [
        "# remove the \"segmentation\" problem (warning message on df performance after many joins and data transformations)\n",
        "new_df = df_with_dummies.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOIxiUAEyBOo"
      },
      "source": [
        "# 1) Modeling: \"rule of thumb\" or hand-predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUu-tssz2ucr"
      },
      "outputs": [],
      "source": [
        "# let's have a time-series or one ticker\n",
        "df_nvda = new_df[new_df.Ticker=='NVDA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "x8zbc8Y5245l",
        "outputId": "bb95d5e0-3650-48b8-fce2-d7736390f253"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_nvda, x=\"Date\", y=\"Close_x\", title='NVDA price')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xPHyYum23OUz",
        "outputId": "11fb87ed-9536-4b46-f4db-37f916549de5"
      },
      "outputs": [],
      "source": [
        "# TRAIN / VALIDATION/ TEST split\n",
        "\n",
        "# Calculate the lengths of each split -- this is not temporal split, but based on the number of observations --> \"classic\" split with no shuffle\n",
        "total_length = len(df_nvda)\n",
        "train_length = int(0.8 * total_length)\n",
        "val_length = int(0.1 * total_length)\n",
        "\n",
        "# Split the data\n",
        "train_data = df_nvda.iloc[:train_length]\n",
        "val_data = df_nvda.iloc[train_length:train_length+val_length]\n",
        "test_data = df_nvda.iloc[train_length+val_length:]\n",
        "\n",
        "# Plot the data\n",
        "fig = px.line(title='NVDA Close price daily for three time intervals Train/Validation/Test')\n",
        "fig.add_scatter(x=train_data['Date'], y=train_data['Close_x'], mode='lines', name='Train', line=dict(color='blue'))\n",
        "fig.add_scatter(x=val_data['Date'], y=val_data['Close_x'], mode='lines', name='Validation', line=dict(color='orange'))\n",
        "fig.add_scatter(x=test_data['Date'], y=test_data['Close_x'], mode='lines', name='Test', line=dict(color='green'))\n",
        "\n",
        "# Update layout to center the title\n",
        "fig.update_layout(title=dict(x=0.5))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "7-QZp5emfqG-",
        "outputId": "5898ce57-de37-4e0e-eab4-3168f37b26f7"
      },
      "outputs": [],
      "source": [
        "# HIST ON NVDA DATA Train/Test/Validation\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add histograms for each split\n",
        "fig.add_trace(go.Histogram(x=train_data['growth_future_30d'], name='Train', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=val_data['growth_future_30d'], name='Validation', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=test_data['growth_future_30d'], name='Test', opacity=0.75))\n",
        "\n",
        "fig.update_layout(barmode='overlay', title='Distribution of growth_future_30d for NVIDIA (NVDA) Growth by Train/Valid/Test sets')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "4yfGUpbZO5bq",
        "outputId": "a7c19f97-20b2-4077-cd38-7b16472e8339"
      },
      "outputs": [],
      "source": [
        "# HIST ON ALL DATA Train/Test/Validation\n",
        "# comment: there are some outliers and hard co compare the distributions\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add histograms for each split\n",
        "fig.add_trace(go.Histogram(x=df_with_dummies[df_with_dummies.split=='train']['growth_future_30d'], name='Train', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=df_with_dummies[df_with_dummies.split=='validation']['growth_future_30d'], name='Validation', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=df_with_dummies[df_with_dummies.split=='test']['growth_future_30d'], name='Test', opacity=0.75))\n",
        "\n",
        "fig.update_layout(barmode='overlay', title='Distribution of growth_future_30d for All tickers Growth by Train/Valid/Test sets')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "uVNA_D8SRaOu",
        "outputId": "99eb23c7-634b-41ee-f553-7db189e23a41"
      },
      "outputs": [],
      "source": [
        "# Assuming df_with_dummies is your DataFrame containing the 'growth_future_5d' variable and 'split' column\n",
        "\n",
        "# Create the histogram\n",
        "fig = px.histogram(new_df,\n",
        "                   x=\"growth_future_30d\",\n",
        "                   color=\"split\",\n",
        "                   marginal=\"box\", # or violin, rug\n",
        "                   )\n",
        "                  #  hover_data=new_df.growth_future_5d)\n",
        "\n",
        "# Show the histogram\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "W8FJKGTxTeRF",
        "outputId": "51cb0b1f-cc5f-40ae-8546-e6616cf556cd"
      },
      "outputs": [],
      "source": [
        "new_df.groupby(by='split')['growth_future_30d'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "XHJnY-hrgc5i",
        "outputId": "cbe85b7d-7b00-45ea-88be-6bcda46a0e08"
      },
      "outputs": [],
      "source": [
        "# is_positive_growth_5d_future: ONLY NVDA stock\n",
        "\n",
        "# Count occurrences of 0 and 1 for each split\n",
        "train_counts = train_data['is_positive_growth_30d_future'].value_counts(normalize=True)*100\n",
        "val_counts = val_data['is_positive_growth_30d_future'].value_counts(normalize=True)*100\n",
        "test_counts = test_data['is_positive_growth_30d_future'].value_counts(normalize=True)*100\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "# # Add stacked bar charts for each split\n",
        "# fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[0], val_counts[0], test_counts[0]], name='0'))\n",
        "# fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[1], val_counts[1], test_counts[1]], name='1'))\n",
        "\n",
        "\n",
        "# Add stacked bar charts for each split\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[0], val_counts[0], test_counts[0]], name='0',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[0], val_counts[0], test_counts[0]]], textposition='auto'))\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[1], val_counts[1], test_counts[1]], name='1',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[1], val_counts[1], test_counts[1]]], textposition='auto'))\n",
        "\n",
        "\n",
        "fig.update_layout(barmode='stack', title='Distribution of is_positive_growth_30d_future by Train/Validation/Test for NVDA stock')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xWb_JFZ-hkfR",
        "outputId": "0dfac33a-13f8-4879-d430-2aebf8871a8a"
      },
      "outputs": [],
      "source": [
        "# ALL STOCKS: train/test/validation is more similar\n",
        "\n",
        "# Count occurrences of 0 and 1 for each split\n",
        "train_counts = df_with_dummies[df_with_dummies.split=='train']['is_positive_growth_30d_future'].value_counts(normalize=True)*100\n",
        "val_counts = df_with_dummies[df_with_dummies.split=='validation']['is_positive_growth_30d_future'].value_counts(normalize=True)*100\n",
        "test_counts = df_with_dummies[df_with_dummies.split=='test']['is_positive_growth_30d_future'].value_counts(normalize=True)*100\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "\n",
        "# Add stacked bar charts for each split\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[0], val_counts[0], test_counts[0]], name='0',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[0], val_counts[0], test_counts[0]]], textposition='auto'))\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[1], val_counts[1], test_counts[1]], name='1',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[1], val_counts[1], test_counts[1]]], textposition='auto'))\n",
        "\n",
        "\n",
        "fig.update_layout(barmode='stack', title='Distribution of is_positive_growth_30d_future by Train/Validation/Test for ALL stocks')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcaqMnIMPssp"
      },
      "source": [
        "# 1) Modeling: \"rule of thumb\" or hand-predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF5tSoLNrpE_"
      },
      "source": [
        "## 1.1) Review all the inputs again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2qCynDQBMpV"
      },
      "outputs": [],
      "source": [
        "# remove the \"segmentation\" problem (warning message on df performance after many joins and data transformations)\n",
        "new_df = df_with_dummies.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZtHf2IDPf_8",
        "outputId": "706860e6-b396-4ac8-b628-70059e9ffae5"
      },
      "outputs": [],
      "source": [
        "# Full dataframe (transformed and truncated to 25 years)\n",
        "new_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "tRAp67SPiyW4",
        "outputId": "a769a076-1539-4b5b-c549-b47fae4b8f3b"
      },
      "outputs": [],
      "source": [
        "# check one record: it has abs. values, text, and numbers\n",
        "new_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "_zvzkXNgjF1O",
        "outputId": "d9412edf-a8dc-40ac-dabd-86e033c78c6e"
      },
      "outputs": [],
      "source": [
        "# time split on train/validation/test: FIXED dates of split, approx. 70%, 15%, 15% split\n",
        "new_df.groupby(['split'])['Date'].agg({'min','max','count'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "QQtiyAyIqfsZ",
        "outputId": "d1848685-328f-4138-bc3b-df61150052fe"
      },
      "outputs": [],
      "source": [
        "# what we try to predict\n",
        "new_df[TO_PREDICT].head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "L8fQBotSi0CQ",
        "outputId": "a9b5a6fa-b1d9-46be-c561-bf665d03e7a9"
      },
      "outputs": [],
      "source": [
        "# to be used as features\n",
        "new_df[NUMERICAL+DUMMIES].head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N012tLusJNx"
      },
      "source": [
        "## 1.2) [Code Snippet 3] Manual \"hand rule\" predictions\n",
        "* CCI (binary, on technical indicator CCI)\n",
        "* growth_1d>1\n",
        "* growth_1d>1 & growth_snp500_1d>1\n",
        "*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1mx1uWgl9Az2",
        "outputId": "978fdfc4-8122-47dc-d83d-53155527488c"
      },
      "outputs": [],
      "source": [
        "# why does it work?\n",
        "# compare a vector (pandas.core.series.Series) with scalar 200 ==> element_wise comparison with the number ==> generate a new DataFrame\n",
        "# (only 5 values)\n",
        "pd.DataFrame(new_df.cci>200).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujwk8Rpxi5jQ"
      },
      "outputs": [],
      "source": [
        "# generate manual predictions\n",
        "# Let's label all prediction features with prefix \"pred\"\n",
        "new_df['pred0_manual_cci'] = (new_df.cci>200).astype(int)\n",
        "new_df['pred1_manual_prev_g1'] = (new_df.growth_30d>1).astype(int)\n",
        "new_df['pred2_manual_prev_g1_and_snp'] = ((new_df['growth_30d'] > 1) & (new_df['growth_snp500_30d'] > 1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPkWi2Mp-hJ_"
      },
      "outputs": [],
      "source": [
        "# TODO 2: find more \"hand rules\" - can get it from decision trees important factors, or randomly build on other most popular macro/tech indicators/ manual_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "G-p0SvKtxU0m",
        "outputId": "ddcd45d6-83a3-4014-d5b9-c78a794cc5d1"
      },
      "outputs": [],
      "source": [
        "new_df[['cci','growth_30d','growth_snp500_30d','pred0_manual_cci','pred1_manual_prev_g1','pred2_manual_prev_g1_and_snp','is_positive_growth_30d_future']].sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqYgFqGLA-Ar",
        "outputId": "4ad783bf-0901-4624-9c79-e5f36b8b189e"
      },
      "outputs": [],
      "source": [
        "PREDICTIONS = [k for k in new_df.keys() if k.startswith('pred')]\n",
        "PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpnYWgiTBd48",
        "outputId": "032a9d0a-94de-438e-86a9-962655bead7b"
      },
      "outputs": [],
      "source": [
        "p = PREDICTIONS[0]\n",
        "part1 = p.split('_')[0] # first prefix before '_'\n",
        "print(f'Full column name: {p}, only first part: {part1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcy-ZKcEx315"
      },
      "outputs": [],
      "source": [
        "# One prediction: do we predict correctly?\n",
        "new_df['is_correct_prediction'] = (new_df.pred0_manual_cci == new_df.is_positive_growth_30d_future)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sCpxLbtEYOG",
        "outputId": "f3764dde-c36e-46b2-93ed-f75574f97eed"
      },
      "outputs": [],
      "source": [
        "new_df[['cci','pred0_manual_cci','is_positive_growth_30d_future','is_correct_prediction']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znAWepdQE4vg",
        "outputId": "d7ada613-5569-4dde-b353-853d483e233e"
      },
      "outputs": [],
      "source": [
        "# check \"Precision\" : the percentage of \"correct\" predictions , WHEN we predict \"1\" (POSITIVE future growth)\n",
        "filter = (new_df.split=='test') & (new_df.pred0_manual_cci==1)\n",
        "new_df[filter].is_correct_prediction.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z4mWTnfFDlc",
        "outputId": "fb8323d4-a3a2-4ec9-bc58-78c1d3e9cf8a"
      },
      "outputs": [],
      "source": [
        "# %% of correct predictions : 54%\n",
        "new_df[filter].is_correct_prediction.value_counts() / len(new_df[filter])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVBAcObrGZzl"
      },
      "outputs": [],
      "source": [
        "# delete this column\n",
        "del new_df[\"is_correct_prediction\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hh7Gd_H_AU3"
      },
      "outputs": [],
      "source": [
        "# generate columns is_correct_\n",
        "for pred in PREDICTIONS:\n",
        "  part1 = pred.split('_')[0] # first prefix before '_'\n",
        "  new_df[f'is_correct_{part1}'] =  (new_df[pred] == new_df.is_positive_growth_30d_future).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elm6SLsVCX8L",
        "outputId": "632e99ac-2783-4ef9-e550-73ad147e9488"
      },
      "outputs": [],
      "source": [
        "# IS_CORRECT dataset\n",
        "IS_CORRECT =  [k for k in new_df.keys() if k.startswith('is_correct_')]\n",
        "IS_CORRECT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "hhxTefjEC0Mi",
        "outputId": "a2808861-e380-4af3-d950-5b6b0ecb6500"
      },
      "outputs": [],
      "source": [
        "# sample of a dataframe\n",
        "new_df[PREDICTIONS+IS_CORRECT+['is_positive_growth_30d_future']].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeKyzptN_hoA",
        "outputId": "8cd79617-3162-4925-f4fd-bfe675e17941"
      },
      "outputs": [],
      "source": [
        "len(new_df[new_df.split=='test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b8gV4iXC9HV",
        "outputId": "352a8cca-ea29-4f5b-aa4b-fb5b1cd65386"
      },
      "outputs": [],
      "source": [
        "# define \"Precision\" for ALL predictions on a Test dataset (~4 last years of trading)\n",
        "for i,column in enumerate(IS_CORRECT):\n",
        "  prediction_column = PREDICTIONS[i]\n",
        "  is_correct_column = column\n",
        "  filter = (new_df.split=='test') & (new_df[prediction_column]==1)\n",
        "  print(f'Prediction column:{prediction_column} , is_correct_column: {is_correct_column}')\n",
        "  print(new_df[filter][is_correct_column].value_counts())\n",
        "  print(new_df[filter][is_correct_column].value_counts()/len(new_df[filter]))\n",
        "\n",
        "  print('---------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yq6jsaZ72x_"
      },
      "source": [
        "## 1.3) [Code Snippet 4 - Advanced] Statistical prediction : ARIMA models with 3 parameters (p,q,r)\n",
        "* Finding best ARIMA params: not used in 2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS9f4TdAbMK9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Set 'Date' as the index\n",
        "df_arima = df_nvda.copy()\n",
        "\n",
        "df_arima.set_index('Date', inplace=True)\n",
        "df_arima.head()\n",
        "\n",
        "# use ONLY time-series values and no other features\n",
        "train_validation = df_arima[df_arima.split.isin(['train','validation'])]['Close_x']\n",
        "test = df_arima[df_arima.split.isin(['test'])]['Close_x']\n",
        "\n",
        "# this is needed to make a decision about investing for 5 days\n",
        "test_is_positive_future_30d = df_arima[df_arima.split.isin(['test'])]['is_positive_growth_30d_future']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3FxpmpYFY1K"
      },
      "outputs": [],
      "source": [
        "# !pip install pmdarima\n",
        "# from pmdarima import auto_arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRkcRkpFblK0"
      },
      "outputs": [],
      "source": [
        "# Hyper parameters optimization\n",
        "# # ~ several minutes to run\n",
        "# # https://miqbalrp.medium.com/exploring-autoarima-in-python-for-multiple-time-series-forecasting-2f3004ba5a49\n",
        "# # https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html\n",
        "# # Auto ARIMA model fitting: iterating across params\n",
        "# best_arima_model = auto_arima(train_validation,\n",
        "#                    seasonal=False,\n",
        "#                    trace=True,\n",
        "#                    start_p=0, start_q=0, # minimum p and q\n",
        "#                    max_p=12, max_q=12,   # maximum p and q\n",
        "#                    D=None,               # let model determine 'D'\n",
        "#                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLEybgl6ptou"
      },
      "outputs": [],
      "source": [
        "# best model specification trained on train_validation\n",
        "# # (p=6, q=2, r=2)\n",
        "# best_arima_model.get_params()['order']\n",
        "\n",
        "# model parameters (\"coef\" for auto-regression (AR) and moving-average (MA))\n",
        "# best_arima_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-0cDnIRtVAa"
      },
      "outputs": [],
      "source": [
        "# need to do 918 predictions for 1 stock\n",
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF2fXpEiprC6"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5shB4BXzmSd"
      },
      "outputs": [],
      "source": [
        "# [last day] this was used to train the model and obtain the \"best\" params\n",
        "train_validation[-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f64nUOemzjsF"
      },
      "outputs": [],
      "source": [
        "# # history as Series and the \"last value\" (current last known data)\n",
        "history = [x for x in train_validation]\n",
        "history[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPUrMBbwz2ws"
      },
      "outputs": [],
      "source": [
        "# [last day] now need to predict for each value of test, using all available history\n",
        "test[-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxaiFmr9D3f5"
      },
      "outputs": [],
      "source": [
        "# slow to predict, can't quickly predict for ALL 33 tickers * 918 observationa (~30k predictions). Let's have only 1 ticker and these periods to predict:\n",
        "# change this to 10 (1 min) or 50 (5min) to run faster\n",
        "\n",
        "PERIODS_TO_PREDICT = 10  # ~2 minute to predict\n",
        "# PERIODS_TO_PREDICT = 500  #VERY SLOW: used for slides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_rMX2StlyYx"
      },
      "outputs": [],
      "source": [
        "# staring to predict at day1 of test dataframe (we SEE the adj_close price and predict 5 periods ahead)\n",
        "df_arima[df_arima.split=='test'].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvKVm7pUGGFR"
      },
      "outputs": [],
      "source": [
        "# 2025: static params, instead of autotuned\n",
        "\n",
        "# p,q,r = best_arima_model.get_params()['order']\n",
        "p,q,r = 6,2,2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bialu8XedRNK",
        "outputId": "dabdaccf-d5f6-4cde-e426-48e202d8d426"
      },
      "outputs": [],
      "source": [
        "# rolling forecast for ARIMA(6,2,2) model\n",
        "# https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
        "\n",
        "%%time\n",
        "\n",
        "# start from all previous history of train_validation\n",
        "history = [x for x in train_validation]\n",
        "predictions = []\n",
        "decisions = []\n",
        "is_correct_decisions = []\n",
        "\n",
        "tp=0 # true positive\n",
        "fp=0 # false positive\n",
        "\n",
        "# walk-forward validation for PERIODS_TO_PREDICT\n",
        "for t in range(PERIODS_TO_PREDICT):\n",
        "  current_adj_close = test[t] # current adj_close price when we do the prediction\n",
        "  current_is_future_growth_30d = test_is_positive_future_30d[t]\n",
        "\n",
        "  model = ARIMA(history, order = (p,q,r)) # substitute best parameters AND RETRAIN the model (very expensive)\n",
        "  model_fit = model.fit()\n",
        "  output = model_fit.forecast(steps=30) # forecast for 5 periods ahead\n",
        "\n",
        "  yhat = output[29] # prediction 30 periods ahead\n",
        "\n",
        "  if output[29] > current_adj_close:\n",
        "    prediction = 1\n",
        "  else:\n",
        "    prediction = 0\n",
        "\n",
        "  is_correct = (prediction==current_is_future_growth_30d).astype(int)\n",
        "\n",
        "  if prediction == 1:\n",
        "    if is_correct ==1:\n",
        "      tp+=1\n",
        "    else:\n",
        "      fp+=1\n",
        "\n",
        "  predictions.append(yhat)\n",
        "\n",
        "  decisions.append(prediction)\n",
        "  is_correct_decisions.append(is_correct)\n",
        "  obs = test[t+6]\n",
        "  history.append(obs) # add last element to history\n",
        "  print(f'step {t}, current_price = {np.round(current_adj_close,1)}, [30 periods] predicted={np.round(output,1)}, expected={np.round(test[t+1:t+29].values,1)}, decision = {prediction}, is_correct = {is_correct} ')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zikx03sODYvx",
        "outputId": "39f589fc-3bb1-4265-fae0-cf1b768dd804"
      },
      "outputs": [],
      "source": [
        "tp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM-nukgUDaoP",
        "outputId": "b89ac2d9-36d9-492b-841b-05b5e7f23588"
      },
      "outputs": [],
      "source": [
        "fp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T5jYhFxDb6r",
        "outputId": "54a10ea8-bfe2-4114-e1d6-7906c4765760"
      },
      "outputs": [],
      "source": [
        "precision = tp / (tp+fp)\n",
        "precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "Uwsjs5lY5i62",
        "outputId": "0814d2fd-2efd-4f25-9ddc-cafddf5dca49"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,8))\n",
        "test\n",
        "plt.plot(train_validation.index[-100:], train_validation.tail(100), color='green', label = 'Train+Validation Stock Price')\n",
        "plt.plot(test.index[5:PERIODS_TO_PREDICT+5], test[5:PERIODS_TO_PREDICT+5], color = 'red', label = 'Real Stock Price')\n",
        "plt.plot(test.index[5:PERIODS_TO_PREDICT+5], predictions, color = 'blue', label = 'Predicted Stock Price (5 periods ahead)')\n",
        "plt.title('NVDA Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('NVDA Stock Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjHY1B-1Bvtf"
      },
      "source": [
        "## 1.4) [Code Snippet 5] Binary Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHrM1sdLdYc"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oYKW8lodlM7"
      },
      "source": [
        "### 1.4.1) Define dataframes AND perform data cleaning\n",
        "* define X_train (dataframe), X_test (dataframe), y_train (series), y_test (series)\n",
        "* replace +-inf. with 0\n",
        "* fill NaNs with 0 (you can drop it too, but will loose a lot of data in our case\n",
        "* remove 1-2% outliers (in each dimension, or only in variable to_predict :: we won't use it for a Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNjsv3RtNjCu"
      },
      "outputs": [],
      "source": [
        "# Decision Tree doesn't like too large and inf. values\n",
        "import numpy as np\n",
        "\n",
        "def remove_infinite_values(X):\n",
        "    \"\"\"\n",
        "    Remove infinite values from the input array.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Input array (NumPy array or array-like)\n",
        "\n",
        "    Returns:\n",
        "    - Array with infinite values removed\n",
        "    \"\"\"\n",
        "    return X[np.isfinite(X).all(axis=1)]\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X is your input data\n",
        "# filtered_X = remove_infinite_values(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wpXBvokZPLTM",
        "outputId": "51e6e797-e1ab-4fe3-fcd8-8bde01d46442"
      },
      "outputs": [],
      "source": [
        "# look carefully for 'count' to be close to total values (or you need to replace NaNs/remove NaNs), and min/max doesn't equal to -+inf.\n",
        "#  it will give you an idea to dig deeper into some features to understand the 'nature' of a problem\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "new_df[NUMERICAL+DUMMIES].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoiZYkfhQa_g",
        "outputId": "b242b5b2-633c-4185-9190-f5b7124a9b35"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets based on the split date\n",
        "features_list = NUMERICAL+DUMMIES\n",
        "to_predict = 'is_positive_growth_30d_future'\n",
        "\n",
        "train_df = new_df[new_df.split.isin(['train','validation'])].copy(deep=True)\n",
        "test_df = new_df[new_df.split.isin(['test'])].copy(deep=True)\n",
        "\n",
        "# ONLY numerical Separate features and target variable for training and testing sets\n",
        "# need Date and Ticker later when merging predictions to the dataset\n",
        "X_train = train_df[features_list+[to_predict,'Date','Ticker']]\n",
        "X_test = test_df[features_list+[to_predict,'Date','Ticker']]\n",
        "\n",
        "print(f'length: X_train {X_train.shape},  X_test {X_test.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46GYMy7KRUB3",
        "outputId": "efe4f797-55b5-4619-814f-b635357af599"
      },
      "outputs": [],
      "source": [
        "# Can't have +-inf values . E.g. ln(volume)=-inf when volume==0 => substitute with 0\n",
        "\n",
        "# Disable SettingWithCopyWarning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Need to fill NaNs somehow\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "\n",
        "print(f'length: X_train_imputed {X_train.shape},  X_test_imputed {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiJKy6vPWB19"
      },
      "outputs": [],
      "source": [
        "# you may want to remove 1-2% outliers based on percentile ==> not used here in Decision Trees\n",
        "def remove_outliers_percentile(X, lower_percentile=1, upper_percentile=99):\n",
        "    \"\"\"\n",
        "    Remove outliers from the input array based on percentiles.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Input array (NumPy array or array-like)\n",
        "    - lower_percentile: Lower percentile threshold (float, default=1)\n",
        "    - upper_percentile: Upper percentile threshold (float, default=99)\n",
        "\n",
        "    Returns:\n",
        "    - Array with outliers removed\n",
        "    \"\"\"\n",
        "    lower_bound = np.percentile(X, lower_percentile, axis=0)\n",
        "    upper_bound = np.percentile(X, upper_percentile, axis=0)\n",
        "    mask = np.logical_and(np.all(X >= lower_bound, axis=1), np.all(X <= upper_bound, axis=1))\n",
        "    return X[mask]\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X is your input data\n",
        "# filtered_X = remove_outliers_percentile(X, lower_percentile=1, upper_percentile=99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-NNrhAKWXr8"
      },
      "outputs": [],
      "source": [
        "X_train_imputed = X_train # we won't use outliers removal to save more data to train: remove_outliers_percentile(X_train)\n",
        "X_test_imputed = X_test # we won't use outliers removal to save more data to test: remove_outliers_percentile(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBXvMVKWWgSc",
        "outputId": "58e64591-3edb-4938-c42c-6030744cefb1"
      },
      "outputs": [],
      "source": [
        "# same shape\n",
        "print(f'length: X_train_imputed {X_train_imputed.shape},  X_test_imputed {X_test_imputed.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6A_zhDLW0aC"
      },
      "outputs": [],
      "source": [
        "y_train = X_train_imputed[to_predict]\n",
        "y_test = X_test_imputed[to_predict]\n",
        "\n",
        "# remove y_train, y_test from X_ dataframes\n",
        "del X_train_imputed[to_predict]\n",
        "del X_test_imputed[to_predict]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUGSkY7yeO5F"
      },
      "source": [
        "### 1.4.2 Estimation of a Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsSxJEireSeW"
      },
      "outputs": [],
      "source": [
        "# INPUTS:\n",
        "# X_train_imputed : CLEAN dataFrame with only numerical features (train+validation periods)\n",
        "# X_test_imputed : CLEAN dataFrame with only numerical features (test periods)\n",
        "\n",
        "# y_train : true values for the train period\n",
        "# y_test  : true values for the test period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcJAw5w9R7pA"
      },
      "outputs": [],
      "source": [
        "# estimation/fit function (using dataframe of features X and what to predict y) --> optimising total accuracy\n",
        "# max_depth is hyperParameter\n",
        "def fit_decision_tree(X, y, max_depth=20):\n",
        "# Initialize the Decision Tree Classifier\n",
        "  clf = DecisionTreeClassifier(max_depth=max_depth)\n",
        "\n",
        "  # Fit the classifier to the training data\n",
        "  clf.fit(X, y)\n",
        "  return clf, X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES96NQpefU2z",
        "outputId": "a8ab7762-6179-463d-a3af-bc3493524ee2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# drop 2 columns before fitting the tree, but we need those columns later for joins\n",
        "clf_20, train_columns = fit_decision_tree(X=X_train_imputed.drop(['Date','Ticker'],axis=1),\n",
        "                           y=y_train,\n",
        "                           max_depth=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClqSfId-gbMW",
        "outputId": "6d059c37-4622-4c78-fe47-3e5a0fce51fb"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "clf_10, train_columns = fit_decision_tree(X=X_train_imputed.drop(['Date','Ticker'],axis=1),\n",
        "                           y=y_train,\n",
        "                           max_depth=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x74N7Brb-IAm"
      },
      "outputs": [],
      "source": [
        "# TODO 3: TRAIN only on train dataset, experiment with trees with depth 1..20 --> find the best one on VALID dataset\n",
        "#       for the \"best\" tree model: find precision on the TEST set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QbUrS7Ygm2G"
      },
      "source": [
        "### 1.4.3 Inference for a Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csUq1CWISRCe"
      },
      "outputs": [],
      "source": [
        "def predict_decision_tree(clf:DecisionTreeClassifier, df_X:pd.DataFrame, y_true: pd.Series):\n",
        "  # Predict the target variable on the test data\n",
        "  y_pred = clf.predict(df_X)\n",
        "\n",
        "  max_depth = clf.tree_.max_depth\n",
        "  # Print the maximum depth\n",
        "  print(\"Maximum depth of the decision tree:\", max_depth)\n",
        "\n",
        "  # Calculate the accuracy/precision of the model\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  print(f'Accuracy ={accuracy}, precision = {precision}')\n",
        "\n",
        "  # resulting df\n",
        "  result_df = pd.concat([df_X, y_true, pd.Series(y_pred, index=df_X.index, name='pred_')], axis=1)\n",
        "\n",
        "  return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ72IOAaTE7N",
        "outputId": "0fc6cb96-f569-4da0-81c0-99d0e41082c6"
      },
      "outputs": [],
      "source": [
        "pred20 = predict_decision_tree(clf_20, X_test_imputed.drop(['Date','Ticker'],axis=1), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "dpPj5Zxqhm5x",
        "outputId": "93648744-6c11-4820-d80f-7dc6add5508b"
      },
      "outputs": [],
      "source": [
        "# Predictions of a decision tree of depth \"20\"\n",
        "pred20.pred_.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37DPFof2h-Cy",
        "outputId": "b049a537-f59c-43bb-9783-c87ba3166d55"
      },
      "outputs": [],
      "source": [
        "pred10 = predict_decision_tree(clf_10, X_test_imputed.drop(['Date','Ticker'],axis=1), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "ZFmjznLr8tbH",
        "outputId": "e41d3275-11f6-45b2-8903-02e803c56641"
      },
      "outputs": [],
      "source": [
        "pred10.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "NYuaQ7k-8eSu",
        "outputId": "aa873b1f-8d35-4d20-a961-65226b90432c"
      },
      "outputs": [],
      "source": [
        "X_test_imputed.join(pred10['pred_']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "x01xCtd9iLif",
        "outputId": "fb24d0fc-fb53-40f1-e07c-6cfb19d83ef4"
      },
      "outputs": [],
      "source": [
        "# Predictions of a decision tree of depth \"10\" : many more \"positive\" predictions\n",
        "pred10.pred_.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "_pgIZ95bmLD3",
        "outputId": "18e6712f-5249-40bd-ac6d-1c0fb5ab2e78"
      },
      "outputs": [],
      "source": [
        "# define a new DF with the SAME index (used for joins)\n",
        "pred20_df = pred20[['pred_']].rename(columns={'pred_': 'pred_tree_clf20'})\n",
        "pred20_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "4iA7XdbPlyQ3",
        "outputId": "10246fa5-d194-4da3-bae7-4542b0fa37e4"
      },
      "outputs": [],
      "source": [
        "# define a new DF with the SAME index (used for joins)\n",
        "pred10_df = pred10[['pred_']].rename(columns={'pred_': 'pred_tree_clf10'})\n",
        "pred10_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U75FIcVJwlEg"
      },
      "source": [
        "### 1.4.4 Features Importance and Tree Visualisation of top levels (for clf10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "wSmvvHAHwsGA",
        "outputId": "bc664c5d-1590-4dbe-ea71-8d8b22b05173"
      },
      "outputs": [],
      "source": [
        "# visualisation: decision tree for a few levels (max_depth variable)\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming clf is your trained DecisionTreeClassifier\n",
        "plt.figure(figsize=(20,10))  # Set the size of the figure\n",
        "plot_tree(clf_10,\n",
        "          filled=True,\n",
        "          feature_names=train_columns,\n",
        "          class_names=['Negative', 'Positive'],\n",
        "          max_depth=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84F-Mk1P2sGb"
      },
      "outputs": [],
      "source": [
        "# Feautures importance function to predict future returns (based on the classifier)\n",
        "# get feature importance from 'clf' (classifier) and 'train_columns' (column names)\n",
        "\n",
        "def get_importances(clf, train_columns):\n",
        "  # Assuming clf is your trained DecisionTreeClassifier\n",
        "  feature_importance = clf.feature_importances_\n",
        "\n",
        "  # Assuming X_train is your training features\n",
        "  feature_names = train_columns\n",
        "\n",
        "  # Create a DataFrame to store feature importance\n",
        "  feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "\n",
        "  # Sort the DataFrame by importance in descending order\n",
        "  feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "  # Print or display the feature importance DataFrame\n",
        "  # print(feature_importance_df)\n",
        "  return feature_importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "kvOEn1v_2uHM",
        "outputId": "5d855bc1-642a-4a92-f6be-36ae3948ac45"
      },
      "outputs": [],
      "source": [
        "get_importances(clf_10, train_columns).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "abAwJp8R27gN",
        "outputId": "10228db9-3f4d-4830-ec54-9c982a79f49e"
      },
      "outputs": [],
      "source": [
        "get_importances(clf_20, train_columns).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM3yxUwxmYpI"
      },
      "source": [
        "### 1.4.5 Merge with the original df for predictions (only when predicted on test dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WgTBvWxidv0",
        "outputId": "988b8762-fcdf-4926-add5-63bfc8af9f34"
      },
      "outputs": [],
      "source": [
        "# current predictions from MANUAL\n",
        "PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "5-Ew-Mpxi7O3",
        "outputId": "166a1a5b-50a9-4861-ad56-6a0f420e7820"
      },
      "outputs": [],
      "source": [
        "new_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjlrnD3h9htb",
        "outputId": "9a95c28b-bb40-4439-f9f0-a1099e5e950e"
      },
      "outputs": [],
      "source": [
        "# index in df is not unique\n",
        "np.sort(new_df.groupby(new_df.index).split.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NSFV3LEC5a7y",
        "outputId": "d799cbc6-405c-4ae6-9e76-12251f2b4b05"
      },
      "outputs": [],
      "source": [
        "# it's hard to join with pred10_df - as index is totally different\n",
        "pred10_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3scA_5KnLbZ"
      },
      "outputs": [],
      "source": [
        "# TODO 4: JOIN predictions with the original dataframe (define a new column):\n",
        "#  so, that there are columns pred_tree_clf10 AND pred_tree_clf20"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
